{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NYC 311 Harvester This project provides a command-line utility for downloading the full NYC 311 service request dataset (dataset id erm2-nwe9 ) from the NYC OpenData Portal using the official bulk CSV export endpoint. The script focuses on a reliable, single-request download flow while adding a few quality-of-life improvements: Automatic discovery of dataset metadata so that generated files include the last update timestamp (or current UTC time when not available). Support for authentication via APP_TOKEN and optional HTTP/HTTPS proxies through standard environment variables. Progress feedback during long-running downloads, with optional verbose mode for detailed tracing. The repository exposes a single script, download_all.py , plus a handful of internal helpers documented in docs/functions.md .","title":"Overview"},{"location":"#nyc-311-harvester","text":"This project provides a command-line utility for downloading the full NYC 311 service request dataset (dataset id erm2-nwe9 ) from the NYC OpenData Portal using the official bulk CSV export endpoint. The script focuses on a reliable, single-request download flow while adding a few quality-of-life improvements: Automatic discovery of dataset metadata so that generated files include the last update timestamp (or current UTC time when not available). Support for authentication via APP_TOKEN and optional HTTP/HTTPS proxies through standard environment variables. Progress feedback during long-running downloads, with optional verbose mode for detailed tracing. The repository exposes a single script, download_all.py , plus a handful of internal helpers documented in docs/functions.md .","title":"NYC 311 Harvester"},{"location":"functions/","text":"Function Reference This document summarizes the helper functions implemented in download_all.py . Each entry mirrors the corresponding in-code docstring. _build_session Create a requests session configured for the Socrata export. Args: app_token: API token read from the APP_TOKEN environment variable. Returns: requests.Session: Session with authentication headers and optional proxies. Raises: RuntimeError: If no API token is supplied. _format_bytes Render a byte count as a human-friendly string. Args: num_bytes: Number of bytes to format. Returns: str: Human-readable value, e.g. \"1.2 GB\" . _fetch_last_update_stamp Return the dataset's last update timestamp formatted for filenames. Args: session: Configured HTTP session with authentication headers. Returns: str | None: Timestamp string ( YYYYMMDDHHMM ) if available, else None . _resolve_output_path Determine the filename to write the download to. Args: requested_path: Path supplied by the user, if any. session: Configured HTTP session used to query metadata. Returns: str: Absolute or relative path where the dataset will be saved. download_bulk_csv Stream the full dataset to disk via the bulk CSV export endpoint. Args: output_path: Destination file path where the CSV is written, or None to derive a timestamped name automatically. chunk_size: Number of bytes to read per iteration from the response stream. verbose: Whether to print incremental download progress to stdout.","title":"Function Reference"},{"location":"functions/#function-reference","text":"This document summarizes the helper functions implemented in download_all.py . Each entry mirrors the corresponding in-code docstring.","title":"Function Reference"},{"location":"functions/#_build_session","text":"Create a requests session configured for the Socrata export. Args: app_token: API token read from the APP_TOKEN environment variable. Returns: requests.Session: Session with authentication headers and optional proxies. Raises: RuntimeError: If no API token is supplied.","title":"_build_session"},{"location":"functions/#_format_bytes","text":"Render a byte count as a human-friendly string. Args: num_bytes: Number of bytes to format. Returns: str: Human-readable value, e.g. \"1.2 GB\" .","title":"_format_bytes"},{"location":"functions/#_fetch_last_update_stamp","text":"Return the dataset's last update timestamp formatted for filenames. Args: session: Configured HTTP session with authentication headers. Returns: str | None: Timestamp string ( YYYYMMDDHHMM ) if available, else None .","title":"_fetch_last_update_stamp"},{"location":"functions/#_resolve_output_path","text":"Determine the filename to write the download to. Args: requested_path: Path supplied by the user, if any. session: Configured HTTP session used to query metadata. Returns: str: Absolute or relative path where the dataset will be saved.","title":"_resolve_output_path"},{"location":"functions/#download_bulk_csv","text":"Stream the full dataset to disk via the bulk CSV export endpoint. Args: output_path: Destination file path where the CSV is written, or None to derive a timestamped name automatically. chunk_size: Number of bytes to read per iteration from the response stream. verbose: Whether to print incremental download progress to stdout.","title":"download_bulk_csv"}]}